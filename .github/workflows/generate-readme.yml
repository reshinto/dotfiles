name: Generate README

on:
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Generate README from repository contents
        run: |
          python - <<'PY'
          from __future__ import annotations
          
          import ast
          import json
          import os
          import re
          from collections import Counter
          from pathlib import Path
          from typing import Iterable
          
          REPO_ROOT = Path.cwd()
          IGNORE_DIR_PARTS = {
              ".git",
              ".venv",
              "venv",
              "env",
              "node_modules",
              "__pycache__",
              "dist",
              "build",
              "coverage",
              ".pytest_cache",
              ".mypy_cache",
              ".idea",
              ".vscode",
          }
          
          LANGUAGE_BY_EXT = {
              ".py": "Python",
              ".ipynb": "Jupyter Notebook",
              ".js": "JavaScript",
              ".jsx": "React JSX",
              ".ts": "TypeScript",
              ".tsx": "React TSX",
              ".mjs": "Modern JavaScript",
              ".cjs": "Node.js CommonJS",
              ".json": "JSON",
              ".java": "Java",
              ".kt": "Kotlin",
              ".kts": "Kotlin Script",
              ".rb": "Ruby",
              ".go": "Go",
              ".rs": "Rust",
              ".php": "PHP",
              ".cs": "C#",
              ".cpp": "C++",
              ".cxx": "C++",
              ".cc": "C++",
              ".c": "C",
              ".h": "C/C++ Header",
              ".hpp": "C++ Header",
              ".mm": "Objective-C++",
              ".m": "Objective-C",
              ".swift": "Swift",
              ".scala": "Scala",
              ".sh": "Shell",
              ".bash": "Shell",
              ".ps1": "PowerShell",
              ".bat": "Batch",
              ".cmd": "Batch",
              ".yml": "YAML",
              ".yaml": "YAML",
              ".toml": "TOML",
              ".ini": "Configuration",
              ".cfg": "Configuration",
              ".conf": "Configuration",
              ".env": "Environment Variables",
              ".md": "Markdown",
              ".mdx": "MDX",
              ".rst": "reStructuredText",
              ".txt": "Text",
              ".html": "HTML",
              ".htm": "HTML",
              ".css": "CSS",
              ".scss": "SCSS",
              ".less": "LESS",
              ".sql": "SQL",
              ".dockerfile": "Docker",
              "dockerfile": "Docker",
              ".gradle": "Gradle",
              ".groovy": "Groovy",
              ".makefile": "Makefile",
              "makefile": "Makefile",
          }
          
          COMMENT_PREFIXES = {
              "hash": {
                  ".py",
                  ".sh",
                  ".bash",
                  ".rb",
                  ".pl",
                  ".pm",
                  ".ps1",
                  ".psm1",
                  ".cfg",
                  ".conf",
                  ".ini",
                  ".toml",
                  ".yaml",
                  ".yml",
              },
              "slash": {
                  ".js",
                  ".jsx",
                  ".ts",
                  ".tsx",
                  ".java",
                  ".kt",
                  ".kts",
                  ".c",
                  ".cc",
                  ".cpp",
                  ".cxx",
                  ".h",
                  ".hpp",
                  ".cs",
                  ".go",
                  ".rs",
                  ".swift",
                  ".scala",
                  ".php",
              },
              "semicolon": {
                  ".sql",
              },
          }
          
          CAPABILITY_KEYWORDS = {
              "flask": "RESTful APIs and lightweight web services",
              "fastapi": "high-performance async APIs",
              "django": "full-stack web application patterns",
              "express": "Node.js HTTP services",
              "nextjs": "React server-side rendering",
              "react": "interactive front-end views",
              "vue": "component-driven front-end interfaces",
              "svelte": "compiled front-end experiences",
              "tailwind": "utility-first styling",
              "pandas": "data analysis workflows",
              "numpy": "numeric and scientific computing",
              "scikit-learn": "machine learning pipelines",
              "tensorflow": "deep learning",
              "pytorch": "deep learning",
              "pytest": "automated test suites",
              "unittest": "automated testing",
              "selenium": "browser automation",
              "beautifulsoup": "HTML parsing and scraping",
              "requests": "HTTP integrations",
              "sqlalchemy": "database access layers",
              "prisma": "database access layers",
              "typeorm": "database access layers",
              "mongoose": "database access layers",
              "click": "command-line interfaces",
              "argparse": "command-line interfaces",
              "boto3": "cloud automation on AWS",
              "azure": "Azure platform tooling",
              "gcloud": "Google Cloud automation",
              "docker": "containerisation",
              "dockerfile": "containerisation",
              "kubernetes": "cluster orchestration",
              "terraform": "infrastructure-as-code",
              "ansible": "configuration automation",
              "airflow": "workflow orchestration",
              "notebook": "exploratory analysis",
              "matplotlib": "visualisation tooling",
              "seaborn": "visualisation tooling",
              "streamlit": "data apps and dashboards",
              "tkinter": "desktop user interfaces",
              "discord.py": "chat bot automation",
              "slack_sdk": "messaging automation",
              "openai": "AI-assisted features",
              "langchain": "LLM orchestration",
          }
          
          IMPORT_SUMMARY_HINTS = {
              "argparse": "parses command-line arguments for flexible execution",
              "csv": "ingests structured CSV data",
              "email": "builds MIME email messages",
              "imaplib": "monitors inbox folders",
              "json": "parses and emits JSON payloads",
              "os": "touches the local filesystem and environment variables",
              "pathlib": "works with filesystem paths",
              "platform": "detects the host operating system",
              "requests": "communicates with HTTP services",
              "smtplib": "sends transactional email via SMTP",
              "subprocess": "invokes system commands",
              "pandas": "structures data with pandas DataFrames",
              "darksky": "retrieves weather insights from Dark Sky",
          }
          
          SHELL_OPERATION_HINTS = {
              "git clone": "clones remote Git repositories into the requested directory",
              "ffmpeg": "converts media files with FFmpeg",
              "python": "chains additional Python utilities",
              "npm": "executes Node.js package scripts",
              "curl": "performs HTTP requests from the shell",
          }
          
          TOPIC_HINTS = {
              "email": "email automation helpers",
              "weather": "weather data retrieval",
              "rename": "bulk file renaming",
              "repo": "repository setup tooling",
              "clone": "repository cloning workflows",
              "video": "media conversion scripts",
              "mp3": "audio extraction utilities",
              "json": "data reshaping from JSON",
              "iex": "market data ingestion",
              "imap": "mailbox management",
          }
          
          EXCLUDED_FEATURE_LANGUAGES = {
              "Markdown",
              "Text",
              "YAML",
              "JSON",
              "Configuration",
              "Environment Variables",
          }
          
          MAX_FEATURES_PER_LANGUAGE = {
              "Python": 20,
              "Shell": 8,
          }

          MAX_FEATURES_DEFAULT = 6
          
          ENTRY_POINT_HINTS = {
              ".py": "python {path}",
              ".sh": "bash {path}",
              ".bash": "bash {path}",
              ".ps1": "pwsh {path}",
              ".bat": "./{path}",
              ".cmd": "./{path}",
          }
          
          STOPWORDS = {
              "about",
              "after",
              "also",
              "another",
              "being",
              "between",
              "both",
              "built",
              "build",
              "cannot",
              "class",
              "classes",
              "data",
              "default",
              "each",
              "file",
              "files",
              "from",
              "have",
              "into",
              "main",
              "module",
              "other",
              "project",
              "provide",
              "provides",
              "return",
              "script",
              "scripts",
              "self",
              "that",
              "their",
              "these",
              "those",
              "using",
              "value",
              "values",
              "when",
              "with",
              "without",
              "utility",
              "utilities",
              "helper",
              "helpers",
              "feature",
              "features",
              "import",
              "text",
              "video",
              "bash",
              "echo",
              "password",
              "input",
              "output",
              "processing",
              "touches",
              "local",
              "filesystem",
              "environment",
              "variables",
              "invokes",
              "commands",
              "coordinates",
              "routines",
              "builds",
              "monitors",
              "sends",
              "transactional",
              "email",
              "messages",
              "server",
              "folder",
              "default",
              "current",
              "function",
              "works",
              "method",
              "key",
              "highlights",
          }
          
          SPECIAL_TOKENS = {
              "api": "API",
              "apis": "APIs",
              "cli": "CLI",
              "csv": "CSV",
              "http": "HTTP",
              "https": "HTTPS",
              "id": "ID",
              "ids": "IDs",
              "imap": "IMAP",
              "json": "JSON",
              "smtp": "SMTP",
              "sql": "SQL",
              "url": "URL",
              "osx": "macOS",
              "windows": "Windows",
              "windows10": "Windows 10",
              "linux": "Linux",
              "ubuntu": "Ubuntu",
              "kali": "Kali",
          }
          
          CAPABILITY_PATTERNS = {
              keyword: re.compile(rf"(?<!\w){re.escape(keyword)}(?!\w)")
              for keyword in CAPABILITY_KEYWORDS
          }
          
          
          def is_binary(path: Path) -> bool:
              try:
                  data = path.read_bytes()
              except Exception:
                  return True
              if not data:
                  return False
              if b"\x00" in data:
                  return True
              text_chars = bytearray({7, 8, 9, 10, 12, 13, 27} | set(range(0x20, 0x100)))
              nontext = sum(ch not in text_chars for ch in data[:1024])
              return nontext / min(len(data), 1024) > 0.30
          
          
          def read_text(path: Path) -> str | None:
              if is_binary(path):
                  return None
              try:
                  return path.read_text(encoding="utf-8", errors="ignore")
              except Exception:
                  return None
          
          
          def relevant_files() -> Iterable[Path]:
              for path in sorted(REPO_ROOT.rglob("*")):
                  if not path.is_file():
                      continue
                  if path.name.startswith(".") and path.suffix not in {".env"}:
                      continue
                  if any(part in IGNORE_DIR_PARTS for part in path.parts[:-1]):
                      continue
                  if path.name.lower() == "readme.md":
                      continue
                  yield path
          
          
          def extension_key(path: Path) -> str:
              suffix = path.suffix.lower()
              if not suffix and path.name.lower() in {"dockerfile", "makefile"}:
                  return path.name.lower()
              return suffix
          
          
          def human_name(path: Path) -> str:
              return path.relative_to(REPO_ROOT).as_posix()
          
          
          def clean_sentence(text: str, max_length: int = 260) -> str:
              text = re.sub(r"\s+", " ", text.strip())
              if len(text) > max_length:
                  text = text[: max_length - 1].rstrip() + "\u2026"
              if text and text[-1] not in ".!?":
                  text += "."
              return text
          
          
          def tokenize_identifier(name: str) -> list[str]:
              tokens = re.findall(r"[A-Z]+(?=[A-Z][a-z]|[0-9]|$)|[A-Z]?[a-z]+|[0-9]+", name)
              if not tokens:
                  tokens = re.split(r"[_\-]+", name)
              return [token for token in tokens if token]
          
          
          def format_identifier(name: str) -> str:
              tokens = tokenize_identifier(name)
              formatted: list[str] = []
              for token in tokens:
                  lower = token.lower()
                  formatted.append(SPECIAL_TOKENS.get(lower, token.capitalize()))
              return " ".join(formatted)
          
          
          def summarise_docstring(doc: str | None) -> str | None:
              if not doc:
                  return None
              doc = doc.strip()
              if not doc:
                  return None
              lines = [line.strip() for line in doc.splitlines() if line.strip()]
              if not lines:
                  return None
              intro = clean_sentence(lines[0])
              bullets: list[str] = []
              for line in lines[1:]:
                  match = re.match(r"^(?:[-*+]|\d+[.)-]?)\s*(.+)$", line)
                  if match:
                      bullet = match.group(1).strip()
                      bullet = re.sub(r"[.]+$", "", bullet)
                      bullets.append(bullet)
              if bullets:
                  intro = intro[:-1] if intro.endswith(".") else intro
                  intro += ". Key highlights: " + ", ".join(bullets[:3]) + "."
              return intro
          
          
          def join_human(items: list[str]) -> str:
              if not items:
                  return ""
              if len(items) == 1:
                  return items[0]
              return ", ".join(items[:-1]) + f" and {items[-1]}"
          
          
          def extract_markdown_summary(text: str) -> tuple[str | None, int]:
              for line in text.splitlines():
                  stripped = line.strip()
                  if stripped.startswith("#"):
                      return clean_sentence(stripped.lstrip("# ")), 3
                  if stripped:
                      return clean_sentence(stripped), 2
              return None, 0
          
          
          def extract_comment_summary(text: str, ext: str) -> tuple[str | None, int]:
              lines = text.splitlines()
              block: list[str] = []
              in_block = False
              for raw in lines[:80]:
                  stripped = raw.strip()
                  if not stripped:
                      if block:
                          break
                      continue
                  if ext in {".sh", ".bash"} and stripped.startswith("#!"):
                      continue
                  if ext in COMMENT_PREFIXES["hash"] and stripped.startswith("#"):
                      block.append(stripped.lstrip("# "))
                      continue
                  if ext in COMMENT_PREFIXES["slash"]:
                      if stripped.startswith("//"):
                          block.append(stripped.lstrip("/ "))
                          continue
                      if stripped.startswith("/*"):
                          in_block = True
                          content = stripped.lstrip("/* ")
                          if content:
                              block.append(content)
                          if stripped.endswith("*/") and len(stripped) > 2:
                              in_block = False
                          continue
                      if in_block:
                          if stripped.endswith("*/"):
                              block.append(stripped[:-2].strip())
                              break
                          block.append(stripped)
                          continue
                  if ext in COMMENT_PREFIXES.get("semicolon", set()) and stripped.startswith("--"):
                      block.append(stripped.lstrip("- "))
                      continue
                  if block:
                      break
                  else:
                      break
              cleaned = " ".join(segment for segment in block if segment)
              cleaned = re.sub(r"\s+", " ", cleaned).strip()
              if not cleaned:
                  return None, 0
              if "copyright" in cleaned.lower() or "license" in cleaned.lower():
                  return None, 0
              return clean_sentence(cleaned), 2
          
          
          def extract_shell_summary(text: str) -> str | None:
              summary = None
              comment_summary, _ = extract_comment_summary(text, ".sh")
              if comment_summary:
                  summary = comment_summary
              operations = [phrase for keyword, phrase in SHELL_OPERATION_HINTS.items() if keyword in text]
              if operations:
                  sentence = "It " + join_human(operations) + "."
                  summary = (summary + " " + sentence if summary else sentence)
              return summary
          
          
          def extract_python_summary(text: str) -> tuple[str | None, int]:
              try:
                  tree = ast.parse(text)
              except Exception:
                  return None, 0
              sentences: list[str] = []
              module_doc = summarise_docstring(ast.get_docstring(tree))
              if module_doc:
                  sentences.append(module_doc)
              imports = set()
              for node in ast.walk(tree):
                  if isinstance(node, ast.Import):
                      for alias in node.names:
                          imports.add(alias.name.split(".")[0])
                  elif isinstance(node, ast.ImportFrom) and node.module:
                      imports.add(node.module.split(".")[0])
              hints = [IMPORT_SUMMARY_HINTS[name] for name in sorted(imports) if name in IMPORT_SUMMARY_HINTS]
              if hints:
                  sentences.append("It " + join_human(hints) + ".")
              class_sentences: list[str] = []
              function_sentences: list[str] = []
              for node in tree.body:
                  if isinstance(node, ast.ClassDef):
                      doc = summarise_docstring(ast.get_docstring(node))
                      if doc:
                          class_sentences.append(doc)
                      else:
                          methods = [
                              format_identifier(child.name)
                              for child in node.body
                              if isinstance(child, ast.FunctionDef) and not child.name.startswith("_")
                          ]
                          if methods:
                              lowered = " ".join(method.lower() for method in methods)
                              qualifier = "key"
                              if any(token in lowered for token in ["windows", "linux", "macos", "ubuntu", "kali"]):
                                  qualifier = "operating-system"
                              display_methods = methods[:4]
                              if len(methods) > 4:
                                  display_methods.append("other helpers")
                              class_sentences.append(
                                  f"The {format_identifier(node.name)} class coordinates {qualifier} routines such as {join_human(display_methods)}."
                              )
                  elif isinstance(node, ast.FunctionDef):
                      doc = summarise_docstring(ast.get_docstring(node))
                      if doc:
                          function_sentences.append(doc)
              sentences.extend(class_sentences[:2])
              if not class_sentences and function_sentences:
                  sentences.append(function_sentences[0])
              if not sentences:
                  return None, 0
              ordered_unique = list(dict.fromkeys(sentences))
              return " ".join(ordered_unique), 3
          
          
          def describe_file(path: Path, text: str | None) -> dict:
              ext = extension_key(path)
              language = LANGUAGE_BY_EXT.get(ext, format_identifier(path.suffix[1:] if path.suffix else path.name))
              summary = None
              quality = 1
              if text:
                  if ext in {".md", ".mdx"}:
                      summary, quality = extract_markdown_summary(text)
                  elif ext == ".py":
                      summary, quality = extract_python_summary(text)
                  elif ext in {".sh", ".bash"}:
                      shell_summary = extract_shell_summary(text)
                      if shell_summary:
                          summary = shell_summary
                          quality = 2
                  if not summary:
                      comment_summary, comment_quality = extract_comment_summary(text, ext)
                      if comment_summary:
                          summary = comment_summary
                          quality = max(quality, comment_quality)
                  if not summary and text:
                      head = " ".join(text.splitlines()[:20])
                      summary = clean_sentence(head) if head else None
                      quality = min(quality, 1)
              if not summary:
                  summary = f"Implements {language.lower()} logic for {format_identifier(path.stem).lower()}."
                  quality = 1
              summary = summary[0].upper() + summary[1:] if summary else summary
              return {
                  "path": human_name(path),
                  "language": language,
                  "summary": summary,
                  "quality": quality,
              }
          
          
          def detect_capabilities(text: str | None, path: Path, capability_counter: Counter) -> None:
              if ".github/workflows" in path.as_posix():
                  capability_counter["ci/cd automation"] += 1
                  return
              if text is None:
                  return
              lower = text.lower()
              for keyword, pattern in CAPABILITY_PATTERNS.items():
                  if pattern.search(lower):
                      capability_counter[CAPABILITY_KEYWORDS[keyword]] += 1
              name = path.name.lower()
              if name in {"dockerfile"} or name.endswith("dockerfile"):
                  capability_counter["containerisation"] += 1
          
          
          def detect_entry_points(path: Path, text: str | None, entries: list[str]) -> None:
              ext = extension_key(path)
              command_template = ENTRY_POINT_HINTS.get(ext)
              if command_template and text:
                  lower = text.lower()
                  if ext == ".py" and "if __name__ == \"__main__\"" in lower:
                      entries.append(command_template.format(path=human_name(path)))
                  elif ext in {".sh", ".bash"} and text.splitlines():
                      first_line = text.splitlines()[0]
                      if first_line.startswith("#!/"):
                          entries.append(command_template.format(path=human_name(path)))
                  elif ext in {".ps1", ".bat", ".cmd"}:
                      entries.append(command_template.format(path=human_name(path)))
              if path.name == "package.json" and text:
                  try:
                      data = json.loads(text)
                      scripts = data.get("scripts") or {}
                      for name, command in scripts.items():
                          entries.append(f"npm run {name}  # {command}")
                  except Exception:
                      pass
          
          
          def detect_dependency_steps(path: Path, steps: list[str]) -> None:
              lower_name = path.name.lower()
              if lower_name == "requirements.txt":
                  steps.append("pip install -r requirements.txt")
              elif lower_name == "pyproject.toml":
                  steps.append("pip install .  # uses pyproject.toml")
              elif lower_name == "environment.yml":
                  steps.append("conda env create -f environment.yml")
              elif lower_name == "package.json":
                  steps.append("npm install")
              elif lower_name == "yarn.lock":
                  steps.append("yarn install")
              elif lower_name == "pnpm-lock.yaml":
                  steps.append("pnpm install")
              elif lower_name == "composer.json":
                  steps.append("composer install")
              elif lower_name == "pom.xml":
                  steps.append("mvn install")
              elif lower_name in {"build.gradle", "build.gradle.kts"}:
                  steps.append("gradle build")
              elif lower_name == "cargo.toml":
                  steps.append("cargo build")
              elif lower_name == "go.mod":
                  steps.append("go mod tidy")
              elif lower_name == "requirements.in":
                  steps.append("pip install -r requirements.in")
          
          
          files = list(relevant_files())
          file_descriptions: list[dict] = []
          language_counter: Counter[str] = Counter()
          capability_counter: Counter[str] = Counter()
          topic_counter: Counter[str] = Counter()
          entry_points: list[str] = []
          dependency_steps: list[str] = []
          
          for path in files:
              ext = extension_key(path)
              language = LANGUAGE_BY_EXT.get(ext)
              if not language and path.suffix:
                  language = format_identifier(path.suffix[1:])
              if not language:
                  language = format_identifier(path.name) or "Text"
              language_counter[language] += 1
          
              text = read_text(path)
              description = describe_file(path, text)
              file_descriptions.append(description)
          
              detect_capabilities(text, path, capability_counter)
              detect_entry_points(path, text, entry_points)
              detect_dependency_steps(path, dependency_steps)
          
              path_lower = description["path"].lower()
              summary_lower = description["summary"].lower()
              matched_topics = set()
              for keyword, label in TOPIC_HINTS.items():
                  if keyword in path_lower or keyword in summary_lower:
                      matched_topics.add(label)
              for label in matched_topics:
                  topic_counter[label] += 1
          
          seen_steps = set()
          ordered_steps = []
          for step in dependency_steps:
              if step not in seen_steps:
                  ordered_steps.append(step)
                  seen_steps.add(step)
          
          seen_entries = set()
          ordered_entries = []
          for entry in entry_points:
              if entry not in seen_entries:
                  ordered_entries.append(entry)
                  seen_entries.add(entry)
          
          
          overview_sections: list[str] = []
          total_files = len(files)
          if language_counter:
              top_languages = [
                  f"{language} ({count} files)" for language, count in language_counter.most_common(4)
              ]
              overview_sections.append(
                  f"This repository curates {total_files} tracked files spanning {join_human(top_languages)}."
              )
          else:
              overview_sections.append(f"This repository curates {total_files} tracked files.")

          if capability_counter:
              capability_line = join_human(
                  [desc for desc, _ in capability_counter.most_common(6)]
              )
              overview_sections.append(
                  f"It showcases automation around {capability_line}."
              )

          if topic_counter:
              topic_line = join_human([label for label, _ in topic_counter.most_common(5)])
              overview_sections.append(
                  f"Expect utilities for {topic_line}."
              )
          
          sorted_descriptions = sorted(
              file_descriptions,
              key=lambda d: (-d["quality"], d["language"], d["path"]),
          )
          features_by_language: dict[str, list[str]] = {}
          for description in sorted_descriptions:
              line = f"- **{description['path']}** â€” {description['summary']}"
              if description["language"] in EXCLUDED_FEATURE_LANGUAGES:
                  continue
              if description["path"].startswith('.github/'):
                  continue
              bucket = features_by_language.setdefault(description["language"], [])
              limit = MAX_FEATURES_PER_LANGUAGE.get(description["language"], MAX_FEATURES_DEFAULT)
              if len(bucket) < limit:
                  bucket.append(line)
          
          language_order = sorted(
              features_by_language.keys(),
              key=lambda lang: -language_counter.get(lang, 0)
          )
          feature_entries: list[str] = []
          while len(feature_entries) < 32 and any(features_by_language.values()):
              for language in language_order:
                  queue = features_by_language.get(language)
                  if queue:
                      feature_entries.append(queue.pop(0))
                  if len(feature_entries) >= 32:
                      break
          
          if not feature_entries:
              feature_entries = ["- Repository files will be summarised here once source code is available."]
          
          getting_started_steps = [
              "Clone the repository and open it in your preferred development environment.",
          ]
          if ordered_steps:
              for step in ordered_steps:
                  getting_started_steps.append(f"Run `{step}` to install dependencies.")
          else:
              if "Python" in language_counter:
                  getting_started_steps.append("Create a virtual environment and install the required Python packages.")
              if "JavaScript" in language_counter or "TypeScript" in language_counter:
                  getting_started_steps.append("Install Node.js dependencies with your preferred package manager.")
              if "Go" in language_counter:
                  getting_started_steps.append("Ensure Go modules are downloaded with `go mod tidy`.")
              if "Rust" in language_counter:
                  getting_started_steps.append("Install Rust toolchain via `rustup` and fetch crates with `cargo fetch`.")
          
          run_section: list[str] = []
          if ordered_entries:
              run_section.append("Use these commands to explore key entry points:")
              for entry in ordered_entries[:10]:
                  run_section.append(f"- `{entry}`")
          else:
              run_section.append(
                  "Inspect the feature list above to identify scripts or services you wish to run; most command-line tools can be executed with their standard runtime (for example `python path/to/script.py` or `npm run <script>`)."
              )
          
          readme_content = f"""# Repository Overview
          
          ## Overview
          {' '.join(overview_sections)}
          
          ## Key Features
          {os.linesep.join(feature_entries)}
          
          ## Getting Started
          {os.linesep.join(f"{idx + 1}. {step}" for idx, step in enumerate(getting_started_steps))}
          
          ## Running the Project
          {os.linesep.join(run_section)}
          """
          
          Path("README.md").write_text(readme_content.strip() + "\n", encoding="utf-8")
          PY

      - name: Commit README if updated
        run: |
          if [[ -n "$(git status --short README.md)" ]]; then
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add README.md
            git commit -m "Update README"
            git push
          else
            echo "No README updates detected."
          fi
